%!TEX root = TableSummarizationDemo.tex

\section{Demonstration Overview} \label{sec:demo} 
In our demonstration, we will show our prototype implementation of a system equipped with smart drill-down. We first describe the prototype implementation, the datasets, and then describe the demonstration scenarios.

\stitle{Prototype Details.} Our system is built as a web-application using NodeJS~\cite{nodejs}, with ExpressJS as the back-end, and AngularJS~\cite{angular} on the front-end. The Rule Finder and Sample Handler components (displayed in Figure~\ref{fig:system}) are coded in Java, and converted into an executable jar which gets called by the web server backend. 

\stitle{Datasets Description.} In our demonstration, we will use two datasets. The first dataset, denoted `Marketing', contains demographic information about potential customers~\cite{dataset1}. A total of $9409$ questionnaires containing $502$ questions were filled out by shopping mall customers in the San Fransisco Bay Area. The dataset is a summary of their responses. Each tuple in the dataset describes a single person, with attributes such as gender, marital status, age, and so on. The second dataset is a US 1990 Census dataset from the UCI Machine Learning Repository~\cite{uciml}. It has 2.5 million tuples, with each tuple corresponding to a person. In both the datasets, numerical columns such as age have been bucketized beforehand. The former would be an example of a dataset that users are not very familiar with, and the latter would be an example of a dataset that users are familiar with.


\stitle{Demonstration Scenarios.} During the demo, we will set up instances of the system set up with the two previously described datasets pre-loaded. We will also have the web user interface opened up in a a browser. Then for each demonstration, we will go though three scenarios one after the other:
\squishlist
\item {\bf Scenario 1: Comparison to drill-down}: To begin with, we will have some canned exploration scenarios in order to familiarize users with the system interface and its adjustable parameters. Through the scenarios, we will demonstrate how smart drill down lets one discover interesting information about a table efficiently, and how the table exploration can be tailored to fit a user's interests. These scenarios will highlight the advantage of smart drill down compared with traditional drill down. 
\item {\bf Scenario 2: Rule Finder Parameters}: We will allow the user to vary parameters shown in the user interface and observe their effects on the rules displayed, as well as response time and accuracy. Increasing the `Number of Rules' parameter will result in a longer rule list being displayed, but will cause an increase in response time. Reducing the `Max Weight' parameter, which allows the system to ignore rules having weight higher than the Max Weight, will speed up the response time of the system, but reducing it too much will result in a suboptimal rule-list being displayed. The third parameter, the weighting function, determines which rules the user finds `interesting'. Using a different weighting function, such as the `Bits' (which gives higher weight to rules containing non-$\star$ values in columns that have a large number of distinct values) will prioritize columns such as `Education' over columns such as `Gender' (since the latter has only two distinct values). The user will also be able to ignore certain columns, or force certain columns to be instantiated in the displayed rules. 
\item {\bf Scenario 3: Sample Handler Parameters}: We will allow users to try out multiple instances of the system initialized with different values of the $minSS$  parameter (recall that $minSS$ is the minimum sample size used by the system when determining which rules to display). This will allow users to observe how decreasing $minSS$ decreases running time but also potentially reduces accuracy of the displayed rules and their counts.
\squishend